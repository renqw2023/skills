#!/bin/bash
###############################################################################
# AIå†…å®¹æ”¶é›†è„šæœ¬ - V2 å¤šæºç‰ˆ
# æ•°æ®æº: Hacker News / Reddit / TechCrunch
# ç”¨æ³•: ./collect-v2.sh [æ—¥æœŸï¼Œæ ¼å¼YYYY-MM-DDï¼Œé»˜è®¤ä¸ºä»Šå¤©]
###############################################################################

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PIPELINE_DIR="$(dirname "$SCRIPT_DIR")"
DATE="${1:-$(date +%Y-%m-%d)}"
OUTPUT_DIR="$PIPELINE_DIR/collected/$DATE"
mkdir -p "$OUTPUT_DIR"

LOG_FILE="$OUTPUT_DIR/collection.log"
RAW_FILE="$OUTPUT_DIR/raw-content.json"
MARKDOWN_FILE="$OUTPUT_DIR/raw-content.md"

log() {
    echo "[$(date '+%H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# åˆå§‹åŒ–JSONå’ŒMarkdown
echo '{"date": "'$DATE'", "sources": []}' > "$RAW_FILE"
cat > "$MARKDOWN_FILE" << EOF
# ğŸ¤– AIå†…å®¹æ”¶é›†æŠ¥å‘Š - $DATE

> â° æ”¶é›†æ—¶é—´: $(date '+%Y-%m-%d %H:%M:%S')  
> ğŸ“Š æ•°æ®æº: Hacker News | Reddit | TechCrunch

---

EOF

log "========== å¼€å§‹æ”¶é›†AIå†…å®¹ =========="
TOTAL=0

###############################################################################
# 1. Hacker News - çƒ­é—¨AIå†…å®¹
###############################################################################
log "ğŸ“¡ [1/3] Hacker News..."

HN_FILE=$(mktemp)
# ä½¿ç”¨ä¸åŒçš„æœç´¢è¯è·å–æ›´çƒ­é—¨çš„å†…å®¹
API_URL="https://hn.algolia.com/api/v1/search?query=AI+OR+GPT+OR+LLM&tags=story&numericFilters=points%3E20&hitsPerPage=20"

if curl -s --max-time 30 "$API_URL" -o "$HN_FILE" 2>/dev/null && jq -e '.hits' "$HN_FILE" > /dev/null 2>&1; then
    COUNT=$(jq '.hits | length' "$HN_FILE")
    log "   âœ… è·å–åˆ° $COUNT æ¡"
    
    ITEMS=$(jq '[.hits[] | select(.points >= 10)] | map({
        title: .title,
        url: (.url // ("https://news.ycombinator.com/item?id=" + .objectID)),
        author: .author,
        points: .points,
        comments: .num_comments,
        time: .created_at,
        source: "Hacker News",
        hn_url: ("https://news.ycombinator.com/item?id=" + .objectID)
    })' "$HN_FILE")
    
    ITEM_COUNT=$(echo "$ITEMS" | jq 'length')
    if [[ $ITEM_COUNT -gt 0 ]]; then
        SOURCE_JSON=$(jq -n --arg name "ğŸ”¥ Hacker News" --arg id "hn-ai" --argjson items "$ITEMS" \
            '{name: $name, id: $id, count: ($items | length), items: $items}')
        jq --argjson source "$SOURCE_JSON" '.sources += [$source]' "$RAW_FILE" > "${RAW_FILE}.tmp" && mv "${RAW_FILE}.tmp" "$RAW_FILE"
        
        {
            echo "## ğŸ”¥ Hacker News - çƒ­é—¨AIå†…å®¹"
            echo ""
            echo "$ITEMS" | jq -r '.[] | 
                "### " + .title + "\n" +
                "- ğŸ“Š **çƒ­åº¦**: â¬†ï¸ " + (.points | tostring) + " points | ğŸ’¬ " + (.comments | tostring) + " comments\n" +
                "- ğŸ‘¤ **ä½œè€…**: @" + .author + "\n" +
                "- ğŸ”— **é“¾æ¥**: [åŸæ–‡](" + .url + ") | [HNè®¨è®º](" + .hn_url + ")\n" +
                "---\n"
            '
        } >> "$MARKDOWN_FILE"
        TOTAL=$((TOTAL + ITEM_COUNT))
    fi
else
    log "   âŒ è·å–å¤±è´¥"
fi
rm -f "$HN_FILE"

###############################################################################
# 2. Reddit - å¤šä¸ªAIç›¸å…³ç¤¾åŒº
###############################################################################
log "ğŸ“¡ [2/3] Reddit AIç¤¾åŒº..."

# Reddit r/ArtificialIntelligence
REDDIT_FILE=$(mktemp)
if curl -s --max-time 30 \
    -H "User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)" \
    "https://www.reddit.com/r/ArtificialIntelligence/top.json?t=day&limit=15" \
    -o "$REDDIT_FILE" 2>/dev/null; then
    
    if jq -e '.data.children' "$REDDIT_FILE" > /dev/null 2>&1; then
        ITEMS=$(jq '[.data.children[] | select(.data.stickied != true and .data.ups > 5)] | map({
            title: .data.title,
            url: .data.url,
            permalink: "https://reddit.com" + .data.permalink,
            author: .data.author,
            upvotes: .data.ups,
            upvote_ratio: .data.upvote_ratio,
            comments: .data.num_comments,
            domain: .data.domain,
            source: "Reddit r/AI"
        })' "$REDDIT_FILE")
        
        ITEM_COUNT=$(echo "$ITEMS" | jq 'length')
        if [[ $ITEM_COUNT -gt 0 ]]; then
            SOURCE_JSON=$(jq -n --arg name "ğŸ¤– Reddit r/AI" --arg id "reddit-ai" --argjson items "$ITEMS" \
                '{name: $name, id: $id, count: ($items | length), items: $items}')
            jq --argjson source "$SOURCE_JSON" '.sources += [$source]' "$RAW_FILE" > "${RAW_FILE}.tmp" && mv "${RAW_FILE}.tmp" "$RAW_FILE"
            
            {
                echo "## ğŸ¤– Reddit r/ArtificialIntelligence"
                echo ""
                echo "$ITEMS" | jq -r '.[] | 
                    "### " + .title + "\n" +
                    "- ğŸ“Š **çƒ­åº¦**: â¬†ï¸ " + (.upvotes | tostring) + " upvotes | ğŸ’¬ " + (.comments | tostring) + " comments\n" +
                    "- ğŸ‘¤ **ä½œè€…**: u/" + .author + " | ğŸ“° " + .domain + "\n" +
                    "- ğŸ”— **é“¾æ¥**: [åŸæ–‡](" + .url + ") | [Reddit](" + .permalink + ")\n" +
                    "---\n"
                '
            } >> "$MARKDOWN_FILE"
            TOTAL=$((TOTAL + ITEM_COUNT))
            log "   âœ… r/AI: $ITEM_COUNT æ¡"
        fi
    fi
fi
rm -f "$REDDIT_FILE"

# Reddit r/singularity
REDDIT_FILE=$(mktemp)
if curl -s --max-time 30 \
    -H "User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)" \
    "https://www.reddit.com/r/singularity/top.json?t=day&limit=10" \
    -o "$REDDIT_FILE" 2>/dev/null; then
    
    if jq -e '.data.children' "$REDDIT_FILE" > /dev/null 2>&1; then
        ITEMS=$(jq '[.data.children[] | select(.data.stickied != true and .data.ups > 5)] | map({
            title: .data.title,
            url: .data.url,
            permalink: "https://reddit.com" + .data.permalink,
            author: .data.author,
            upvotes: .data.ups,
            comments: .data.num_comments,
            domain: .data.domain,
            source: "Reddit r/singularity"
        })' "$REDDIT_FILE")
        
        ITEM_COUNT=$(echo "$ITEMS" | jq 'length')
        if [[ $ITEM_COUNT -gt 0 ]]; then
            SOURCE_JSON=$(jq -n --arg name "ğŸš€ Reddit r/singularity" --arg id "reddit-singularity" --argjson items "$ITEMS" \
                '{name: $name, id: $id, count: ($items | length), items: $items}')
            jq --argjson source "$SOURCE_JSON" '.sources += [$source]' "$RAW_FILE" > "${RAW_FILE}.tmp" && mv "${RAW_FILE}.tmp" "$RAW_FILE"
            
            {
                echo "## ğŸš€ Reddit r/singularity"
                echo ""
                echo "$ITEMS" | jq -r '.[] | 
                    "### " + .title + "\n" +
                    "- ğŸ“Š **çƒ­åº¦**: â¬†ï¸ " + (.upvotes | tostring) + " upvotes | ğŸ’¬ " + (.comments | tostring) + " comments\n" +
                    "- ğŸ‘¤ **ä½œè€…**: u/" + .author + " | ğŸ“° " + .domain + "\n" +
                    "- ğŸ”— **é“¾æ¥**: [åŸæ–‡](" + .url + ") | [Reddit](" + .permalink + ")\n" +
                    "---\n"
                '
            } >> "$MARKDOWN_FILE"
            TOTAL=$((TOTAL + ITEM_COUNT))
            log "   âœ… r/singularity: $ITEM_COUNT æ¡"
        fi
    fi
fi
rm -f "$REDDIT_FILE"

###############################################################################
# 3. TechCrunch - AIåˆ†ç±» (ä½¿ç”¨ RSS è½¬ JSON æœåŠ¡)
###############################################################################
log "ğŸ“¡ [3/3] TechCrunch..."

# ä½¿ç”¨rss2jsonæœåŠ¡è·å–TechCrunch AIå†…å®¹
TECHCRUNCH_FILE=$(mktemp)
if curl -s --max-time 30 \
    "https://api.rss2json.com/v1/api.json?rss_url=https://techcrunch.com/category/artificial-intelligence/feed/" \
    -o "$TECHCRUNCH_FILE" 2>/dev/null; then
    
    if jq -e '.items' "$TECHCRUNCH_FILE" > /dev/null 2>&1; then
        ITEMS=$(jq '.items[:10] | map({
            title: .title,
            url: .link,
            author: .author,
            published: .pubDate,
            description: (.description | gsub("<[^>]+>"; "") | .[:200]),
            source: "TechCrunch AI"
        })' "$TECHCRUNCH_FILE")
        
        ITEM_COUNT=$(echo "$ITEMS" | jq 'length')
        if [[ $ITEM_COUNT -gt 0 ]]; then
            SOURCE_JSON=$(jq -n --arg name "ğŸ“° TechCrunch AI" --arg id "techcrunch-ai" --argjson items "$ITEMS" \
                '{name: $name, id: $id, count: ($items | length), items: $items}')
            jq --argjson source "$SOURCE_JSON" '.sources += [$source]' "$RAW_FILE" > "${RAW_FILE}.tmp" && mv "${RAW_FILE}.tmp" "$RAW_FILE"
            
            {
                echo "## ğŸ“° TechCrunch - AIæ¿å—"
                echo ""
                echo "$ITEMS" | jq -r '.[] | 
                    "### " + .title + "\n" +
                    "- ğŸ‘¤ **ä½œè€…**: " + .author + "\n" +
                    "- ğŸ“… **å‘å¸ƒ**: " + .published + "\n" +
                    "- ğŸ“ **æ‘˜è¦**: " + .description + "...\n" +
                    "- ğŸ”— **é“¾æ¥**: [é˜…è¯»åŸæ–‡](" + .url + ")\n" +
                    "---\n"
                '
            } >> "$MARKDOWN_FILE"
            TOTAL=$((TOTAL + ITEM_COUNT))
            log "   âœ… TechCrunch: $ITEM_COUNT æ¡"
        fi
    fi
else
    log "   âš ï¸ TechCrunch RSSæš‚æ—¶ä¸å¯ç”¨"
fi
rm -f "$TECHCRUNCH_FILE"

###############################################################################
# å®Œæˆç»Ÿè®¡
###############################################################################
log "========== æ”¶é›†å®Œæˆ =========="
log "ğŸ“Š æ€»è®¡: $TOTAL æ¡å†…å®¹"

echo "" >> "$MARKDOWN_FILE"
echo "---" >> "$MARKDOWN_FILE"
echo "" >> "$MARKDOWN_FILE"
echo "ğŸ“Š **æ±‡æ€»**: å…±æ”¶é›† $TOTAL æ¡AIç›¸å…³å†…å®¹" >> "$MARKDOWN_FILE"

echo ""
echo "âœ… æ”¶é›†å®Œæˆ! å…± $TOTAL æ¡"
echo "ğŸ“„ $MARKDOWN_FILE"
