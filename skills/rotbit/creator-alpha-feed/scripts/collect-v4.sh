#!/bin/bash
###############################################################################
# AIå†…å®¹æ”¶é›†è„šæœ¬ - V4 å®Œæ•´ç‰ˆ
# æ•°æ®æº: Hacker News / Reddit / TechCrunch / Twitter (browseræŠ“å–)
# ç”¨æ³•: ./collect-v4.sh [--twitter] [æ—¥æœŸ]
###############################################################################

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PIPELINE_DIR="$(dirname "$SCRIPT_DIR")"
DATE="${2:-$(date +%Y-%m-%d)}"
ENABLE_TWITTER=false

# è§£æå‚æ•°
if [[ "$1" == "--twitter" ]]; then
    ENABLE_TWITTER=true
fi

OUTPUT_DIR="$PIPELINE_DIR/collected/$DATE"
mkdir -p "$OUTPUT_DIR"

LOG_FILE="$OUTPUT_DIR/collection.log"
RAW_FILE="$OUTPUT_DIR/raw-content.json"
MARKDOWN_FILE="$OUTPUT_DIR/raw-content.md"

log() {
    echo "[$(date '+%H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# åˆå§‹åŒ–JSONå’ŒMarkdown
echo '{"date": "'$DATE'", "sources": []}' > "$RAW_FILE"
cat > "$MARKDOWN_FILE" << EOF
# ğŸ¤– AIå†…å®¹æ”¶é›†æŠ¥å‘Š - $DATE

> â° æ”¶é›†æ—¶é—´: $(date '+%Y-%m-%d %H:%M:%S')  
> ğŸ“Š æ•°æ®æº: Hacker News | Reddit | TechCrunch ${ENABLE_TWITTER:+'| Twitter (browser)'}

---

EOF

log "========== AIå†…å®¹æ”¶é›†å¼€å§‹ =========="
log "æ—¥æœŸ: $DATE"
log "Twitteræ”¶é›†: $([ "$ENABLE_TWITTER" = true ] && echo 'å·²å¯ç”¨' || echo 'å·²è·³è¿‡')"
TOTAL=0

###############################################################################
# 1. Hacker News
###############################################################################
log "ğŸ“¡ [1/4] Hacker News..."

HN_FILE=$(mktemp)
API_URL="https://hn.algolia.com/api/v1/search?query=AI+OR+GPT+OR+LLM&tags=story&numericFilters=points%3E15&hitsPerPage=12"

if curl -s --max-time 30 "$API_URL" -o "$HN_FILE" 2>/dev/null && jq -e '.hits' "$HN_FILE" > /dev/null 2>&1; then
    ITEMS=$(jq '[.hits[] | select(.points >= 10)] | map({
        title: .title,
        url: (.url // ("https://news.ycombinator.com/item?id=" + .objectID)),
        author: .author,
        points: .points,
        comments: .num_comments,
        source: "Hacker News",
        hn_url: ("https://news.ycombinator.com/item?id=" + .objectID)
    })' "$HN_FILE")
    
    ITEM_COUNT=$(echo "$ITEMS" | jq 'length')
    if [[ $ITEM_COUNT -gt 0 ]]; then
        SOURCE_JSON=$(jq -n --arg name "ğŸ”¥ Hacker News" --arg id "hn-ai" --argjson items "$ITEMS" \
            '{name: $name, id: $id, count: ($items | length), items: $items}')
        jq --argjson source "$SOURCE_JSON" '.sources += [$source]' "$RAW_FILE" > "${RAW_FILE}.tmp" && mv "${RAW_FILE}.tmp" "$RAW_FILE"
        
        {
            echo "## ğŸ”¥ Hacker News - çƒ­é—¨AIå†…å®¹"
            echo ""
            echo "$ITEMS" | jq -r '.[] | 
                "### " + .title + "\n" +
                "- ğŸ“Š â¬†ï¸ " + (.points | tostring) + " points | ğŸ’¬ " + (.comments | tostring) + " | ğŸ‘¤ @" + .author + "\n" +
                "- ğŸ”— [åŸæ–‡](" + .url + ") | [HN](" + .hn_url + ")\n" +
                "---\n"
            '
        } >> "$MARKDOWN_FILE"
        TOTAL=$((TOTAL + ITEM_COUNT))
        log "   âœ… $ITEM_COUNT æ¡"
    fi
else
    log "   âŒ å¤±è´¥"
fi
rm -f "$HN_FILE"

###############################################################################
# 2. TechCrunch
###############################################################################
log "ğŸ“¡ [2/4] TechCrunch..."

TC_FILE=$(mktemp)
if curl -s --max-time 30 \
    "https://api.rss2json.com/v1/api.json?rss_url=https://techcrunch.com/category/artificial-intelligence/feed/" \
    -o "$TC_FILE" 2>/dev/null && jq -e '.items' "$TC_FILE" > /dev/null 2>&1; then
    
    ITEMS=$(jq '.items[:6] | map({
        title: .title,
        url: .link,
        author: .author,
        published: .pubDate,
        description: (.description | gsub("<[^>]+>"; "") | .[:150]),
        source: "TechCrunch AI"
    })' "$TC_FILE")
    
    ITEM_COUNT=$(echo "$ITEMS" | jq 'length')
    if [[ $ITEM_COUNT -gt 0 ]]; then
        SOURCE_JSON=$(jq -n --arg name "ğŸ“° TechCrunch" --arg id "techcrunch-ai" --argjson items "$ITEMS" \
            '{name: $name, id: $id, count: ($items | length), items: $items}')
        jq --argjson source "$SOURCE_JSON" '.sources += [$source]' "$RAW_FILE" > "${RAW_FILE}.tmp" && mv "${RAW_FILE}.tmp" "$RAW_FILE"
        
        {
            echo "## ğŸ“° TechCrunch - AIæ–°é—»"
            echo ""
            echo "$ITEMS" | jq -r '.[] | 
                "### " + .title + "\n" +
                "- ğŸ‘¤ " + .author + " | ğŸ“… " + .published[:10] + "\n" +
                "- ğŸ“ " + .description + "...\n" +
                "- ğŸ”— [é˜…è¯»](" + .url + ")\n" +
                "---\n"
            '
        } >> "$MARKDOWN_FILE"
        TOTAL=$((TOTAL + ITEM_COUNT))
        log "   âœ… $ITEM_COUNT æ¡"
    fi
else
    log "   âš ï¸ ä¸å¯ç”¨"
fi
rm -f "$TC_FILE"

###############################################################################
# 3. Reddit
###############################################################################
log "ğŸ“¡ [3/4] Reddit..."

REDDIT_COUNT=0
for SUBREDDIT in "ArtificialIntelligence" "singularity"; do
    RD_FILE=$(mktemp)
    if curl -s --max-time 25 \
        -H "User-Agent: Mozilla/5.0" \
        "https://www.reddit.com/r/${SUBREDDIT}/top.json?t=day&limit=6" \
        -o "$RD_FILE" 2>/dev/null && jq -e '.data.children' "$RD_FILE" > /dev/null 2>&1; then
        
        ITEMS=$(jq '[.data.children[] | select(.data.stickied != true and .data.ups > 5)] | map({
            title: .data.title,
            url: .data.url,
            permalink: "https://reddit.com" + .data.permalink,
            author: .data.author,
            upvotes: .data.ups,
            comments: .data.num_comments,
            source: "Reddit r/'$SUBREDDIT'"
        })' "$RD_FILE")
        
        ITEM_COUNT=$(echo "$ITEMS" | jq 'length')
        if [[ $ITEM_COUNT -gt 0 ]]; then
            SOURCE_JSON=$(jq -n --arg name "ğŸ¤– Reddit r/$SUBREDDIT" --arg id "reddit-$SUBREDDIT" --argjson items "$ITEMS" \
                '{name: $name, id: $id, count: ($items | length), items: $items}')
            jq --argjson source "$SOURCE_JSON" '.sources += [$source]' "$RAW_FILE" > "${RAW_FILE}.tmp" && mv "${RAW_FILE}.tmp" "$RAW_FILE"
            
            if [[ $REDDIT_COUNT -eq 0 ]]; then
                echo "## ğŸ¤– Reddit - AIç¤¾åŒº" >> "$MARKDOWN_FILE"
                echo "" >> "$MARKDOWN_FILE"
            fi
            
            echo "**r/$SUBREDDIT**" >> "$MARKDOWN_FILE"
            echo "" >> "$MARKDOWN_FILE"
            echo "$ITEMS" | jq -r '.[] | 
                "- **" + .title + "**\n" +
                "  â¬†ï¸ " + (.upvotes | tostring) + " | ğŸ’¬ " + (.comments | tostring) + " | [é“¾æ¥](" + .url + ")\n"
            ' >> "$MARKDOWN_FILE"
            
            TOTAL=$((TOTAL + ITEM_COUNT))
            REDDIT_COUNT=$((REDDIT_COUNT + ITEM_COUNT))
        fi
    fi
    rm -f "$RD_FILE"
done

if [[ $REDDIT_COUNT -gt 0 ]]; then
    log "   âœ… $REDDIT_COUNT æ¡"
    echo "" >> "$MARKDOWN_FILE"
    echo "---" >> "$MARKDOWN_FILE"
    echo "" >> "$MARKDOWN_FILE"
fi

###############################################################################
# 4. Twitter (å¯é€‰ï¼Œéœ€è¦browserå·¥å…·)
###############################################################################
log "ğŸ“¡ [4/4] Twitter..."

if [[ "$ENABLE_TWITTER" == true ]]; then
    log "   ğŸŒ åˆ›å»ºTwitteræ”¶é›†æŒ‡å—..."
    
    # åˆ›å»ºTwitteræ”¶é›†ä»»åŠ¡æ–‡ä»¶
    cat > "$OUTPUT_DIR/twitter-tasks.md" << EOF
# ğŸ¦ Twitteræ”¶é›†ä»»åŠ¡ - $DATE

## å¾…æ”¶é›†çš„Twitterè´¦å·

åœ¨OpenClawä¸­æ‰§è¡Œä»¥ä¸‹å‘½ä»¤:

### 1. OpenAIå›¢é˜Ÿ
\`\`\`
browser open "https://nitter.net/sama"
browser snapshot
browser open "https://nitter.net/gdb"
browser snapshot
\`\`\`

### 2. AIç ”ç©¶äººå‘˜
\`\`\`
browser open "https://nitter.net/karpathy"
browser snapshot
browser open "https://nitter.net/DrJimFan"
browser snapshot
\`\`\`

### 3. AIè¯é¢˜æœç´¢
\`\`\`
browser open "https://nitter.net/search?f=tweets&q=GPT+Claude+AI&since=$DATE"
browser snapshot
\`\`\`

## æ”¶é›†å†…å®¹æ ¼å¼

å°†æˆªå›¾/å†…å®¹ä¿å­˜åˆ°: \`$OUTPUT_DIR/twitter-content.md\`

æ ¼å¼:
\`\`\`markdown
## Twitter @sama - $DATE

### æ¨æ–‡1
**çƒ­åº¦**: X likes, Y retweets
> æ¨æ–‡å†…å®¹...
**é€‚åˆå…¬ä¼—å·**: [æ˜¯/å¦] - åŸå› 
\`\`\`
EOF

    {
        echo "## ğŸ¦ Twitter (å¾…æ”¶é›†)"
        echo ""
        echo "âš ï¸ **éœ€è¦æ‰‹åŠ¨/browserå·¥å…·æ”¶é›†**"
        echo ""
        echo "ğŸ“‹ **æ”¶é›†æŒ‡å—**: \`$OUTPUT_DIR/twitter-tasks.md\`"
        echo ""
        echo "**æ¨èè´¦å·**:\n- @sama (OpenAI)\n- @karpathy (AIç ”ç©¶å‘˜)\n- @DrJimFan (NVIDIA)"
        echo ""
        echo "**å¿«é€Ÿå‘½ä»¤**:\n\`\`\`\nbrowser open \"https://nitter.net/sama\"\nbrowser snapshot\n\`\`\`"
        echo ""
        echo "---"
        echo ""
    } >> "$MARKDOWN_FILE"
    
    log "   âœ… ä»»åŠ¡æ–‡ä»¶å·²åˆ›å»º"
else
    log "   â­ï¸ å·²è·³è¿‡ (ä½¿ç”¨ --twitter å¯ç”¨)"
    {
        echo "## ğŸ¦ Twitter"
        echo ""
        echo "â­ï¸ **å·²è·³è¿‡** - ä½¿ç”¨ \`--twitter\` å‚æ•°å¯ç”¨browseræ”¶é›†"
        echo ""
        echo "**å¯ç”¨æ–¹å¼**:\n\`\`\`\n./collect-v4.sh --twitter\n\`\`\`"
        echo ""
        echo "---"
        echo ""
    } >> "$MARKDOWN_FILE"
fi

###############################################################################
# å®Œæˆ
###############################################################################
log "========== æ”¶é›†å®Œæˆ =========="
log "ğŸ“Š æ€»è®¡: $TOTAL æ¡"

echo "" >> "$MARKDOWN_FILE"
echo "---" >> "$MARKDOWN_FILE"
echo "" >> "$MARKDOWN_FILE"
echo "ğŸ“Š **æ±‡æ€»**: å…± $TOTAL æ¡AIç›¸å…³å†…å®¹" >> "$MARKDOWN_FILE"

echo ""
echo "âœ… æ”¶é›†å®Œæˆ! å…± $TOTAL æ¡"
echo "ğŸ“„ $MARKDOWN_FILE"

if [[ "$ENABLE_TWITTER" == true ]]; then
    echo "ğŸ¦ Twitterä»»åŠ¡: $OUTPUT_DIR/twitter-tasks.md"
fi
