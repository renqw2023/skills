---
name: Redis
description: Use Redis effectively for caching, queues, and data structures with proper expiration and persistence.
metadata: {"clawdbot":{"emoji":"ðŸ”´","requires":{"anyBins":["redis-cli"]},"os":["linux","darwin","win32"]}}
---

## Expiration (Memory Leaks)

- Keys without TTL live foreverâ€”set expiry on every cache key: `SET key value EX 3600`
- Can't add TTL after SET without another commandâ€”use `SETEX` or `SET ... EX`
- `EXPIRE` resets on key update by defaultâ€”`SET` removes TTL; use `SET ... KEEPTTL` (Redis 6+)
- Lazy expiration: expired keys removed on accessâ€”may consume memory until touched
- `SCAN` with large database: expired keys still show until cleanup cycle runs

## Data Structures I Underuse

- Sorted sets for rate limiting: `ZADD limits:{user} {now} {request_id}` + `ZREMRANGEBYSCORE` for sliding window
- HyperLogLog for unique counts: `PFADD visitors {ip}` uses 12KB for billions of uniques
- Streams for queues: `XADD`, `XREAD`, `XACK`â€”better than LIST for reliable queues
- Hashes for objects: `HSET user:1 name "Alice" email "a@b.com"`â€”more memory efficient than JSON string

## Atomicity Traps

- `GET` then `SET` is not atomicâ€”another client can modify between; use `INCR`, `SETNX`, or Lua
- `SETNX` for locks: `SET lock:resource {token} NX EX 30`â€”NX = only if not exists
- `WATCH`/`MULTI`/`EXEC` for optimistic lockingâ€”transaction aborts if watched key changed
- Lua scripts are atomicâ€”use for complex operations: `EVAL "script" keys args`

## Pub/Sub Limitations

- Messages not persistedâ€”subscribers miss messages sent while disconnected
- At-most-once deliveryâ€”no acknowledgment, no retry
- Use Streams for reliable messagingâ€”`XREAD BLOCK` + `XACK` pattern
- Pub/Sub across cluster: message goes to all nodesâ€”works but adds overhead

## Persistence Configuration

- RDB (snapshots): fast recovery, but data loss between snapshotsâ€”default every 5min
- AOF (append log): less data loss, slower recoveryâ€”`appendfsync everysec` is good balance
- Both off = pure cacheâ€”acceptable if data can be regenerated
- `BGSAVE` for manual snapshotâ€”doesn't block but forks process, needs memory headroom

## Memory Management (Critical)

- `maxmemory` must be setâ€”without it, Redis uses all RAM, then swap = disaster
- Eviction policies: `allkeys-lru` for cache, `volatile-lru` for mixed, `noeviction` for persistent data
- `INFO memory` shows usageâ€”monitor `used_memory` vs `maxmemory`
- Large keys hurt evictionâ€”one 1GB key evicts poorly; prefer many small keys

## Clustering

- Hash slots: keys distributed by hashâ€”same slot required for multi-key operations
- Hash tags: `{user:1}:profile` and `{user:1}:sessions` go to same slotâ€”use for related keys
- No cross-slot `MGET`/`MSET`â€”error unless all keys in same slot
- `MOVED` redirect: client must followâ€”use cluster-aware client library

## Common Patterns

- Cache-aside: check Redis, miss â†’ fetch DB â†’ write Redisâ€”standard caching
- Write-through: write DB + Redis togetherâ€”keeps cache fresh
- Rate limiter: `INCR requests:{ip}:{minute}` with `EXPIRE`â€”simple fixed window
- Distributed lock: `SET ... NX EX` + unique tokenâ€”verify token on release

## Connection Management

- Connection pooling: reuse connectionsâ€”creating is expensive
- Pipeline commands: send batch without waitingâ€”reduces round trips
- `QUIT` on shutdownâ€”graceful disconnect
- Sentinel or Cluster for HAâ€”single Redis is SPOF

## Common Mistakes

- No TTL on cache keysâ€”memory grows until OOM
- Using as primary database without persistenceâ€”data loss on restart
- Blocking operations in single-threaded Redisâ€”`KEYS *` blocks everything; use `SCAN`
- Storing large blobsâ€”Redis is RAM; 100MB values are expensive
- Ignoring `maxmemory`â€”production Redis without limit will crash host
