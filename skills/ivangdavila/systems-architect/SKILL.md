---
name: Systems Architect
description: Design infrastructure, networks, and cloud systems with integration, reliability, and security patterns.
metadata: {"clawdbot":{"emoji":"ğŸŒ","os":["linux","darwin","win32"]}}
---

# Systems Architecture Rules

## Infrastructure Design
- Design for failure at every layer â€” hardware fails, networks partition, regions go down
- Redundancy costs money, downtime costs more â€” calculate acceptable risk
- Prefer managed services for undifferentiated work â€” run less, build more
- Infrastructure as code from day one â€” manual changes drift and break
- Immutable infrastructure beats patching â€” replace, don't repair

## Cloud Architecture
- Multi-AZ minimum, multi-region for critical systems â€” availability zones fail together sometimes
- Right-size first, auto-scale second â€” baseline must be correct
- Reserved capacity for steady load, spot/preemptible for bursts â€” cost optimization requires planning
- Egress costs add up â€” keep traffic within regions when possible
- Cloud vendor lock-in is real â€” abstract where escape matters, accept where it doesn't

## Networking
- Private subnets for workloads, public only for load balancers â€” minimize attack surface
- VPC peering and transit gateways for multi-account â€” plan topology before scaling
- DNS for service discovery â€” hardcoded IPs break migrations
- Zero trust: authenticate and encrypt internal traffic â€” perimeter security isn't enough
- Network segmentation limits blast radius â€” flat networks let attackers roam

## Integration Patterns
- APIs for synchronous, queues for asynchronous â€” match pattern to requirements
- Event-driven for loose coupling â€” producers don't know consumers
- Service mesh for complex microservices â€” observability and security at network layer
- Rate limiting and backpressure protect systems â€” don't let slow consumers crash fast producers
- Dead letter queues for failed messages â€” don't lose data, process later

## Reliability
- Define SLOs before building â€” what does "up" mean for this system?
- Error budgets allow controlled risk â€” 99.9% means 8 hours downtime per year is acceptable
- Blast radius reduction: cell-based architecture â€” limit how many users one failure affects
- Chaos engineering in staging first â€” break things intentionally before production breaks accidentally
- Runbooks for every alert â€” 3 AM isn't debugging time

## Disaster Recovery
- RTO (recovery time) and RPO (data loss) are business decisions â€” architect for the requirement
- Backups aren't recovery until tested â€” restore regularly
- Hot/warm/cold standby each have trade-offs â€” cost vs speed of recovery
- Cross-region replication for critical data â€” single region is single point of failure
- DR drills reveal real problems â€” plan meets reality

## Security
- Defense in depth: multiple barriers â€” one layer will fail
- Least privilege for services too â€” not just users
- Secrets management centralized â€” no secrets in code, config files, or environment variables in images
- Audit logging for compliance and forensics â€” you'll need it after a breach
- Patch aggressively â€” known vulnerabilities are actively exploited

## Monitoring and Observability
- Metrics, logs, and traces together â€” each tells part of the story
- Alerting on symptoms, not causes â€” users down matters, CPU high might not
- Dashboards for each service with golden signals â€” latency, traffic, errors, saturation
- Distributed tracing across services â€” follow requests end to end
- Log aggregation with retention policy â€” balance cost and forensic needs

## Capacity Planning
- Measure current baseline before projecting â€” can't scale what you don't measure
- Load test to find breaking points â€” theory differs from reality
- Capacity leads demand â€” scaling takes time, be ahead
- Cost modeling for growth scenarios â€” 10x users is rarely 10x cost
- Review quarterly at minimum â€” patterns change

## Migration and Evolution
- Strangler fig pattern for legacy replacement â€” route traffic gradually
- Blue-green or canary for infrastructure changes â€” test in production safely
- Database migrations are hardest â€” plan data migration separately
- Rollback plans before rollout â€” assume failure, prepare for it
- Communicate maintenance windows â€” surprises damage trust
