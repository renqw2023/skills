---
name: Elasticsearch
description: Query and index Elasticsearch with proper mappings, analyzers, and search patterns.
metadata: {"clawdbot":{"emoji":"ðŸ”","requires":{"anyBins":["curl"]},"os":["linux","darwin","win32"]}}
---

## Mapping Mistakes

- Always define explicit mappingsâ€”dynamic mapping guesses wrong (first "123" makes field integer, later "abc" fails)
- `text` for full-text search, `keyword` for exact match/aggregationsâ€”using text for IDs breaks filters
- Can't change field type after indexingâ€”must reindex to new index with correct mapping
- Set `dynamic: "strict"` to reject unmapped fieldsâ€”catches typos in field names

## Text vs Keyword

- `text` is analyzed (tokenized, lowercased)â€”"Quick Brown" matches search for "quick"
- `keyword` is exact bytesâ€”"Quick Brown" only matches exactly "Quick Brown"
- Need both? Use multi-field: `"title": { "type": "text", "fields": { "raw": { "type": "keyword" }}}`
- Sort/aggregate on `title.raw`, search on `title`

## Query vs Filter Context

- Query context calculates relevance scoreâ€”expensive, use for search ranking
- Filter context is yes/noâ€”cacheable, use for exact conditions (status, date ranges)
- Combine: `bool.must` for scoring, `bool.filter` for filtering without scoring
- Range queries on dates/numbers almost always belong in filter, not query

## Analyzers

- `standard` analyzer lowercases and removes punctuationâ€”fine for most text
- `keyword` analyzer keeps exact stringâ€”use for codes, SKUs, emails
- Language analyzers (`english`) stem wordsâ€”"running" matches "run"
- Test analyzer with `_analyze` endpoint before indexingâ€”surprises in production hurt

## Nested vs Object

- Object type flattens arraysâ€”`{"tags": [{"key":"a","val":1}, {"key":"b","val":2}]}` becomes `tags.key: [a,b], tags.val: [1,2]`
- Flattened loses associationâ€”query `key=a AND val=2` incorrectly matches above
- Use `nested` type to preserve object boundariesâ€”requires `nested` query wrapper
- Nested is expensiveâ€”avoid for high-cardinality arrays

## Pagination Traps

- `from` + `size` limited to 10,000 hitsâ€”deep pagination fails
- `search_after` for deep paginationâ€”requires consistent sort, typically `_id`
- Scroll API for bulk exportâ€”keeps point-in-time view, but ties up resources
- Don't use scroll for user paginationâ€”search_after is correct choice

## Bulk Operations

- Never index documents one-by-oneâ€”use `_bulk` API, 5-15MB batches
- Bulk format: newline-delimited JSON, action line then document line
- Check response for partial failuresâ€”bulk can succeed overall with individual doc errors
- Set `refresh=false` during bulk loadsâ€”refresh after batch completes

## Performance

- `_source: false` with `stored_fields` if you don't need full documentâ€”reduces I/O
- Use `filter` for cacheable conditionsâ€”Elasticsearch caches filter results
- Avoid leading wildcards (`*term`)â€”forces full scan; use `reverse` field for suffix search
- `profile: true` shows query execution breakdownâ€”find slow clauses

## Sharding

- Shard size 10-50GB optimalâ€”too small = overhead, too large = slow recovery
- Number of shards fixed at creationâ€”can't reshard without reindexing
- Replicas for read throughput and availabilityâ€”set based on query load
- Start with 1 shard for small indicesâ€”over-sharding kills performance

## Index Management

- Use index templatesâ€”new indices get consistent mappings and settings
- Use aliases for zero-downtime reindexingâ€”point alias to new index after reindex
- ILM (Index Lifecycle Management) for time-seriesâ€”auto-rollover, delete old indices
- Close unused indices to free memoryâ€”closed index uses no heap

## Aggregations

- `terms` agg needs `keyword` fieldâ€”text fields fail or give garbage
- Default `size: 10` on terms aggâ€”increase to get all buckets, or use composite
- Cardinality is approximate (HyperLogLog)â€”exact count requires scanning all docs
- Nested aggs require `nested` wrapperâ€”matches nested query pattern

## Common Errors

- "cluster_block_exception"â€”disk > 85%, cluster goes read-only; clear disk, reset with `_cluster/settings`
- "version conflict"â€”concurrent update; retry with `retry_on_conflict` or use optimistic locking
- "circuit_breaker_exception"â€”query uses too much memory; reduce aggregation scope
- Mapping explosion from dynamic fieldsâ€”set `index.mapping.total_fields.limit` and use strict mapping
