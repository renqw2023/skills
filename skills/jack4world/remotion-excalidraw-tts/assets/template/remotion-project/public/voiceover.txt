很多智能体看起来很聪明，但隔天就失忆。

问题往往不在于模型不够强，而在于它缺少一种“长期记忆”：可检索、可复用、还能随着使用不断更新。

OpenClaw 想做的，也不是一个只会聊天的机器人。
它更像一个能动手的数字助手：可以操作你的设备，能长期记住你的偏好，还能在合适的时候主动发起任务。

要做到这一点，关键是“上下文供给”。
你可以把上下文理解成：模型在这一刻能看到、能依赖的外部信息。
上下文越好，行动就越稳。

我们可以把上下文分成四类。
第一，长期知识：例如你的技术栈偏好、常用工具、写作风格、以及一些稳定的事实。
第二，任务记忆：一个长周期任务里，产生的中间决策、观察、以及阶段性产物。
第三，会话历史：你们聊过的完整过程。
第四，外部资源：代码库、技术文档、网页、以及 API 规范等随用随查的信息。

接下来，我们看 OpenClaw 的第一条路线：文件型记忆。
它把记忆写成 Markdown 文件，文件就是真实之源。
优点是透明、可控、好迁移：你打开文件就能看见它记住了什么。

但是，文件多了就需要检索。
于是系统会做索引：扫描文件、把内容分块、做向量嵌入，再结合关键词搜索，把最相关的片段召回。
这样既能搜到关键词，也能按语义相似度找到“意思相近”的内容。

它的问题也很现实：很多时候你得先想起来要去搜。
你不搜，它就不来。
体验上像是：资料库很强，但不够主动。

于是，memory lancedb 插件登场。
它把长期记忆做成一条闭环，让记忆系统更像智能体的一部分。

对话开始前，会自动 recall。
它会到记忆库里检索与你当前问题最相关的内容，然后把结果注入到提示词上下文。
你提问的那一刻，模型先被喂到“该想起的事”。

对话结束后，会自动 capture。
系统会从刚才的对话里提炼出值得记住的句子，做 embedding，把文本变成向量。
然后连同分类和元数据，一起写入 LanceDB。
这样，今天聊到的关键事实，明天还能被找回来。

你也可以手动调用三个工具。
memory recall 用来搜索。
memory store 用来保存。
memory forget 用来删除。

这让记忆不再只是档案，而是可用的、可维护的知识。

把链路串起来，就是：recall 召回相关记忆，帮助模型更快进入状态；执行任务；结束后 capture 提炼关键事实；embedding 把文本变成向量；写入 LanceDB；下一次对话再次召回。

这就是为什么很多个人智能体会偏爱 LanceDB 这类本地优先的向量存储：轻量、无服务、适合把非结构化知识变成可检索的长期记忆。

下一步，我们就进到代码里，逐个验证：插件入口在哪里，配置项怎么写，表结构长什么样，以及 auto recall 和 auto capture 到底在会话的哪个时刻触发。