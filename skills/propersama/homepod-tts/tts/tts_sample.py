"""
HomePod TTS ç¤ºä¾‹è„šæœ¬
ä½¿ç”¨ Qwen3-TTS ç”Ÿæˆå¸¦æƒ…ç»ªçš„è¯­éŸ³

ä½¿ç”¨å‰è¯·é…ç½®ï¼š
1. è®¾ç½® REF_AUDIO å’Œ REF_TEXT ä¸ºä½ çš„å‚è€ƒéŸ³é¢‘
2. æ ¹æ®éœ€è¦è°ƒæ•´ EMOTIONS å­—å…¸

ç”¨æ³•ï¼š
    python3 tts_sample.py -t "è¦åˆæˆçš„æ–‡å­—" -o output.wav
"""

import torch
import soundfile as sf
import argparse

# ========== éœ€é…ç½®çš„å‚æ•° ==========
# å‚è€ƒéŸ³é¢‘è·¯å¾„ï¼ˆ.wavæ ¼å¼ï¼Œå»ºè®® 5-30 ç§’ï¼‰
REF_DIR = "~/homepod-tts/tts/your_ref_audio/"
REF_AUDIO = REF_DIR + "your_reference_audio.wav"
REF_TEXT = "ä½ çš„å‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡å­—å†…å®¹"

# ========== æƒ…ç»ªé…ç½® ==========
EMOTIONS = {
    "default": "å¼€å¿ƒï¼Œçƒ­æƒ…ï¼Œè¯­é€Ÿç¨å¿«ï¼Œå……æ»¡æ´»åŠ›",
    "happy": "éå¸¸å¼€å¿ƒï¼Œå…´é«˜é‡‡çƒˆï¼Œè¯­è°ƒè½»å¿«ï¼Œå£°éŸ³ç”œç¾",
    "excited": "å…´å¥‹ï¼Œæ¿€åŠ¨ï¼Œè¯­é€Ÿå¿«ï¼Œå……æ»¡çƒ­æƒ…",
    "sad": "æ‚²ä¼¤ï¼Œä½æ²‰ï¼Œè¯­è°ƒç¼“æ…¢ï¼Œå¸¦ç€å¿§æ„",
    "angry": "ç”Ÿæ°”ï¼Œæ„¤æ€’ï¼Œè¯­è°ƒä¸¥å‰ï¼Œå£°éŸ³ä½æ²‰æœ‰åŠ›",
    "surprised": "æƒŠè®¶ï¼Œæ„å¤–ï¼Œè¯­è°ƒä¸Šæ‰¬ï¼Œç•¥å¸¦å›å‘³",
    "serious": "ä¸¥è‚ƒï¼Œè®¤çœŸï¼Œè¯­è°ƒå¹³ç¨³ï¼Œæ²‰ç¨³æœ‰åŠ›",
    "gentle": "æ¸©æŸ”ï¼Œè½»æŸ”ï¼Œè¯­è°ƒèˆ’ç¼“ï¼Œæ¸©æš–äº²åˆ‡",
    "calm": "å¹³é™ï¼Œæ·¡å®šï¼Œè¯­è°ƒå¹³ç¨³ï¼Œä»å®¹ä¸è¿«",
}

# æƒ…ç»ªå…³é”®è¯æ˜ å°„ï¼ˆæ ¹æ®ä½ çš„éœ€æ±‚ä¿®æ”¹ï¼‰
EMOTION_KEYWORDS = {
    "happy": ["å¼€å¿ƒ", "é«˜å…´", "å¿«ä¹", "å¤ªå¥½äº†", "nice", "å“ˆå“ˆ"],
    "excited": ["æ¿€åŠ¨", "å…´å¥‹", "åŠ æ²¹", "å†²é¸­", "æ²¸è…¾"],
    "sad": ["éš¾è¿‡", "ä¼¤å¿ƒ", "æ‚²ä¼¤", "å“­äº†", "å¿ƒç—›"],
    "angry": ["ç”Ÿæ°”", "æ„¤æ€’", "å¯æ¶", "è®¨åŒ", "æ°”æ­»"],
    "surprised": ["æƒŠè®¶", "éœ‡æƒŠ", "å§æ§½", "ä»€ä¹ˆ", "å±…ç„¶"],
    "serious": ["è­¦å‘Š", "æ³¨æ„", "ä¸¥è‚ƒ", "è®¤çœŸ"],
    "gentle": ["æ™šå®‰", "æ—©ä¸Šå¥½", "æ¸©æŸ”", "çˆ±ä½ "],
    "calm": ["æ²¡å…³ç³»", "æ·¡å®š", "ç¨³ä½", "ä¸æ€¥"],
}

def detect_emotion(text):
    """æ ¹æ®æ–‡æœ¬å†…å®¹è‡ªåŠ¨è¯†åˆ«æƒ…ç»ª"""
    emotion_scores = {}
    
    for emotion, keywords in EMOTION_KEYWORDS.items():
        score = sum(1 for keyword in keywords if keyword in text)
        if score > 0:
            emotion_scores[emotion] = score
    
    if emotion_scores:
        best_emotion = max(emotion_scores, key=emotion_scores.get)
        print(f"ğŸ­ æ£€æµ‹åˆ°æƒ…ç»ª: {best_emotion}")
        return EMOTIONS.get(best_emotion, EMOTIONS["default"])
    
    print("ğŸ­ ä½¿ç”¨é»˜è®¤æƒ…ç»ª")
    return EMOTIONS["default"]

def main():
    parser = argparse.ArgumentParser(description="TTS è¯­éŸ³ç”Ÿæˆç¤ºä¾‹")
    parser.add_argument("-t", "--text", required=True, help="è¦åˆæˆçš„æ–‡å­—")
    parser.add_argument("-o", "--output", default="output.wav", help="è¾“å‡ºæ–‡ä»¶å")
    parser.add_argument("-e", "--emotion", default=None, help="æŒ‡å®šæƒ…ç»ªï¼ˆå¯é€‰ï¼‰")
    args = parser.parse_args()
    
    # å±•å¼€è·¯å¾„
    import os
    ref_audio = os.path.expanduser(REF_AUDIO)
    
    # æ£€æŸ¥å‚è€ƒéŸ³é¢‘æ˜¯å¦å­˜åœ¨
    if not os.path.exists(ref_audio):
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°å‚è€ƒéŸ³é¢‘: {ref_audio}")
        print("è¯·é…ç½® REF_AUDIO ä¸ºæ­£ç¡®çš„å‚è€ƒéŸ³é¢‘è·¯å¾„")
        return
    
    print(f"ğŸ“ å‚è€ƒéŸ³é¢‘: {ref_audio}")
    
    # å°è¯•å¯¼å…¥ qwen_ttsï¼ˆç”¨æˆ·éœ€è‡ªè¡Œå®‰è£…ï¼‰
    try:
        from qwen_tts import Qwen3TTSModel
    except ImportError:
        print("âŒ é”™è¯¯: æœªå®‰è£… qwen-tts")
        print("è¯·å®‰è£…: pip install qwen-tts")
        return
    
    # ç¡®å®šæƒ…ç»ª
    if args.emotion and args.emotion in EMOTIONS:
        instruct = EMOTIONS[args.emotion]
        print(f"ğŸ­ ä½¿ç”¨æŒ‡å®šæƒ…ç»ª: {args.emotion}")
    else:
        instruct = detect_emotion(args.text)
    
    print(f"ğŸ“ æƒ…ç»ªæŒ‡ä»¤: {instruct}")
    print("ğŸš€ åŠ è½½æ¨¡å‹...")
    
    # åŠ è½½æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
    model = Qwen3TTSModel.from_pretrained(
        "Qwen/Qwen3-TTS-12Hz-0___6B-Base",
        dtype=torch.float32,
        low_cpu_mem_usage=True,
    )
    
    print("ğŸµ ç”Ÿæˆè¯­éŸ³...")
    wavs, sr = model.generate_voice_clone(
        text=args.text,
        language="Chinese",
        ref_audio=ref_audio,
        ref_text=REF_TEXT,
        instruct=instruct,
        do_sample=True,
        temperature=0.9,
        repetition_penalty=1.1,
    )
    
    # ä¿å­˜
    sf.write(args.output, wavs[0], sr)
    audio_info = sf.info(args.output)
    duration = round(audio_info.duration, 1)
    
    print(f"ğŸ‰ å®Œæˆ: {args.output}")
    print(f"â±ï¸ AUDIO_DURATION:{duration}")

if __name__ == "__main__":
    main()
